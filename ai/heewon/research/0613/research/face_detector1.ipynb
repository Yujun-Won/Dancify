{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Face Detection with MediaPipe Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install -q mediapipe==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BlskiiyGDC"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4aPO-hvbw3r"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "# def _normalized_to_pixel_coordinates(\n",
        "#     normalized_x: float, normalized_y: float, image_width: int,\n",
        "#     image_height: int) -> Union[None, Tuple[int, int]]:\n",
        "#   \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
        "\n",
        "#   # Checks if the float value is between 0 and 1.\n",
        "#   def is_valid_normalized_value(value: float) -> bool:\n",
        "#     return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
        "#                                                       math.isclose(1, value))\n",
        "\n",
        "#   if not (is_valid_normalized_value(normalized_x) and\n",
        "#           is_valid_normalized_value(normalized_y)):\n",
        "#     # TODO: Draw coordinates even if it's outside of the image bounds.\n",
        "#     return None\n",
        "#   x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
        "#   y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
        "#   return x_px, y_px\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes and keypoints on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  annotated_image = image.copy()\n",
        "  height, width, _ = image.shape\n",
        "\n",
        "  for detection in detection_result.detections:\n",
        "    # Draw bounding_box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x, bbox.origin_y\n",
        "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "    cv2.rectangle(annotated_image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "    # # Draw keypoints\n",
        "    # for keypoint in detection.keypoints:\n",
        "    #   keypoint_px = _normalized_to_pixel_coordinates(keypoint.x, keypoint.y,\n",
        "    #                                                  width, height)\n",
        "    #   color, thickness, radius = (0, 255, 0), 2, 2\n",
        "    #   cv2.circle(annotated_image, keypoint_px, thickness, color, radius)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    category_name = category.category_name\n",
        "    category_name = '' if category_name is None else category_name\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = category_name + ' (' + str(probability) + ')'\n",
        "    text_location = (MARGIN + bbox.origin_x,\n",
        "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "    cv2.putText(annotated_image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "width 720.0, height 1280.0, fps 30.0\n"
          ]
        }
      ],
      "source": [
        "#재생할 파일 \n",
        "VIDEO_FILE_PATH = '../../0612/spicy_karina.mp4'\n",
        "\n",
        "# 동영상 파일 열기\n",
        "cap = cv2.VideoCapture(VIDEO_FILE_PATH)\n",
        "\n",
        "#잘 열렸는지 확인\n",
        "if cap.isOpened() == False:\n",
        "    print ('Can\\'t open the video (%d)' % (VIDEO_FILE_PATH))\n",
        "    exit()\n",
        "\n",
        "titles = ['orig']\n",
        "#윈도우 생성 및 사이즈 변경\n",
        "for t in titles:\n",
        "    cv2.namedWindow(t)\n",
        "\n",
        "#재생할 파일의 넓이 얻기\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "#재생할 파일의 높이 얻기\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "#재생할 파일의 프레임 레이트 얻기\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print('width {0}, height {1}, fps {2}'.format(width, height, fps))\n",
        "\n",
        "#XVID가 제일 낫다고 함.\n",
        "#linux 계열 DIVX, XVID, MJPG, X264, WMV1, WMV2.\n",
        "#windows 계열 DIVX\n",
        "#저장할 비디오 코덱\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "#저장할 파일 이름\n",
        "filename = './spicy_karina_mosaic.mp4'\n",
        "\n",
        "#파일 stream 생성\n",
        "out = cv2.VideoWriter(filename, fourcc, fps, (int(width), int(height)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yl_Oiye4mUuo"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# STEP 2: Create an FaceDetector object.\n",
        "base_options = python.BaseOptions(model_asset_path='detector.tflite')\n",
        "options = vision.FaceDetectorOptions(base_options=base_options)\n",
        "detector = vision.FaceDetector.create_from_options(options)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if frame is None:\n",
        "        break;\n",
        "    \n",
        "    frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
        "\n",
        "    # STEP 4: Detect faces in the input image.\n",
        "    detection_result = detector.detect(frame)\n",
        "\n",
        "    # STEP 5: Process the detection result. In this case, visualize it.\n",
        "    image_copy = np.copy(frame.numpy_view())\n",
        "    annotated_image = visualize(image_copy, detection_result)\n",
        "    rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    cv2.imshow('image',rgb_annotated_image)\n",
        "    out.write(rgb_annotated_image)\n",
        "    \n",
        "    if cv2.waitKey(1) == 27:\n",
        "        break;\n",
        "\n",
        "#재생 파일 종료\n",
        "cap.release()\n",
        "#저장 파일 종료\n",
        "out.release()\n",
        "#윈도우 종료\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
